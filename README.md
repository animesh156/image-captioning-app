
# ğŸ–¼ï¸ Image Captioning App

Upload an image and get an AI-generated caption using a pre-trained BLIP (Bootstrapped Language-Image Pretraining) model.

## ğŸš€ Features

- Upload `.jpg`, `.jpeg`, or `.png` image files.
- Generates natural language captions for images using BLIP model.
- Powered by HuggingFace Transformers and Streamlit.
- Responsive and clean UI.

## ğŸ› ï¸ Tech Stack

- Python
- [Streamlit](https://streamlit.io/)
- [HuggingFace Transformers](https://huggingface.co/transformers/)
- BLIP model (`Salesforce/blip-image-captioning-base`)
- PIL (Python Imaging Library)
- PyTorch

## ğŸ“‚ Project Structure

```
image-captioning-app/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ caption_generator.py       # Core captioning logic using BLIP model
â”‚
|
â”‚
â”œâ”€â”€ main.py                        # Streamlit app entry point
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # Project documentation (this file)
```

## ğŸ§ª Setup Instructions

1. **Clone the repo**
```bash
git clone https://github.com/your-username/image-captioning-app.git
cd image-captioning-app
```


2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Run the app**
```bash
streamlit run main.py
```

## ğŸ–¼ï¸ Example Screenshot





## ğŸ”® Future Improvements

- Support for multiple captioning models
- Add image preprocessing options (resize, crop)
- Download caption as `.txt` or share on social media
- Dockerize for easier deployment

---

Made with â¤ï¸ using Streamlit and HuggingFace
